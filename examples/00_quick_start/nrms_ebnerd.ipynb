{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "\n",
    "In this notebook, we illustrate how to use the Neural News Recommendation with Multi-Head Self-Attention ([NRMS](https://aclanthology.org/D19-1671/)). The implementation is taken from the [recommenders](https://github.com/recommenders-team/recommenders) repository. We have simply stripped the model to keep it cleaner.\n",
    "\n",
    "We use a small dataset, which is downloaded from [recsys.eb.dk](https://recsys.eb.dk/). All the datasets are stored in the folder path ```~/ebnerd_data/*```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\anaconda3\\envs\\DeepLearning\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\danie\\anaconda3\\envs\\DeepLearning\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import polars as pl\n",
    "\n",
    "from ebrec.utils._constants import (\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "    DEFAULT_SUBTITLE_COL,\n",
    "    DEFAULT_LABELS_COL,\n",
    "    DEFAULT_TITLE_COL,\n",
    "    DEFAULT_USER_COL,\n",
    ")\n",
    "\n",
    "from ebrec.utils._behaviors import (\n",
    "    create_binary_labels_column,\n",
    "    sampling_strategy_wu2019,\n",
    "    add_known_user_column,\n",
    "    add_prediction_scores,\n",
    "    truncate_history,\n",
    ")\n",
    "from ebrec.evaluation import MetricEvaluator, AucScore, NdcgScore, MrrScore\n",
    "from ebrec.utils._articles import convert_text2encoding_with_transformers\n",
    "from ebrec.utils._polars import concat_str_columns, slice_join_dataframes\n",
    "from ebrec.utils._articles import create_article_id_to_value_mapping\n",
    "from ebrec.utils._nlp import get_transformers_word_embeddings\n",
    "from ebrec.utils._python import write_submission_file, rank_predictions_by_score\n",
    "\n",
    "from ebrec.models.newsrec_pytorch.dataloader import NRMSDataLoader\n",
    "from ebrec.models.newsrec_pytorch.model_config import hparams_nrms\n",
    "from ebrec.models.newsrec_pytorch import NRMSModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ebnerd_from_path(path: Path, history_size: int = 30) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Load ebnerd - function\n",
    "    \"\"\"\n",
    "    df_history = (\n",
    "        pl.scan_parquet(path.joinpath(\"history.parquet\"))\n",
    "        .select(DEFAULT_USER_COL, DEFAULT_HISTORY_ARTICLE_ID_COL)\n",
    "        .pipe(\n",
    "            truncate_history,\n",
    "            column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "            history_size=history_size,\n",
    "            padding_value=0,\n",
    "            enable_warning=False,\n",
    "        )\n",
    "    )\n",
    "    df_behaviors = (\n",
    "        pl.scan_parquet(path.joinpath(\"behaviors.parquet\"))\n",
    "        .collect()\n",
    "        .pipe(\n",
    "            slice_join_dataframes,\n",
    "            df2=df_history.collect(),\n",
    "            on=DEFAULT_USER_COL,\n",
    "            how=\"left\",\n",
    "        )\n",
    "    )\n",
    "    return df_behaviors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate labels\n",
    "We sample a few just to get started. For testset we just make up a dummy column with 0 and 1 - this is not the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\"~/ebnerd_data\").expanduser()\n",
    "DATASPLIT = \"ebnerd_small\"\n",
    "DUMP_DIR = PATH.joinpath(\"downloads1\")\n",
    "DUMP_DIR.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we sample the dataset, just to keep it smaller. Also, one can simply add the testset similary to the validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>labels</th></tr><tr><td>u32</td><td>list[i32]</td><td>list[i64]</td><td>list[i64]</td><td>u32</td><td>list[i8]</td></tr></thead><tbody><tr><td>1690313</td><td>[9769404, 9770638, â€¦ 9770799]</td><td>[9778939, 9779968, â€¦ 9780019]</td><td>[9780020]</td><td>174132250</td><td>[0, 0, â€¦ 0]</td></tr><tr><td>1191654</td><td>[9767336, 9769244, â€¦ 9769684]</td><td>[9767909, 9771127, â€¦ 9772045]</td><td>[9771127]</td><td>318242444</td><td>[0, 1, â€¦ 0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 6)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ user_id â”† article_id_fixed  â”† article_ids_invie â”† article_ids_clic â”† impression_id â”† labels      â”‚\n",
       "â”‚ ---     â”† ---               â”† w                 â”† ked              â”† ---           â”† ---         â”‚\n",
       "â”‚ u32     â”† list[i32]         â”† ---               â”† ---              â”† u32           â”† list[i8]    â”‚\n",
       "â”‚         â”†                   â”† list[i64]         â”† list[i64]        â”†               â”†             â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 1690313 â”† [9769404,         â”† [9778939,         â”† [9780020]        â”† 174132250     â”† [0, 0, â€¦ 0] â”‚\n",
       "â”‚         â”† 9770638, â€¦        â”† 9779968, â€¦        â”†                  â”†               â”†             â”‚\n",
       "â”‚         â”† 9770799]          â”† 9780019]          â”†                  â”†               â”†             â”‚\n",
       "â”‚ 1191654 â”† [9767336,         â”† [9767909,         â”† [9771127]        â”† 318242444     â”† [0, 1, â€¦ 0] â”‚\n",
       "â”‚         â”† 9769244, â€¦        â”† 9771127, â€¦        â”†                  â”†               â”†             â”‚\n",
       "â”‚         â”† 9769684]          â”† 9772045]          â”†                  â”†               â”†             â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COLUMNS = [\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "]\n",
    "HISTORY_SIZE = 10\n",
    "FRACTION = 0.01\n",
    "\n",
    "df_train = (\n",
    "    ebnerd_from_path(PATH.joinpath(DATASPLIT, \"train\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(\n",
    "        sampling_strategy_wu2019,\n",
    "        npratio=4,\n",
    "        shuffle=True,\n",
    "        with_replacement=True,\n",
    "        seed=123,\n",
    "    )\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "# =>\n",
    "df_validation = (\n",
    "    ebnerd_from_path(PATH.joinpath(DATASPLIT, \"validation\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>title</th><th>subtitle</th><th>last_modified_time</th><th>premium</th><th>body</th><th>published_time</th><th>image_ids</th><th>article_type</th><th>url</th><th>ner_clusters</th><th>entity_groups</th><th>topics</th><th>category</th><th>subcategory</th><th>category_str</th><th>total_inviews</th><th>total_pageviews</th><th>total_read_time</th><th>sentiment_score</th><th>sentiment_label</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>datetime[Î¼s]</td><td>bool</td><td>str</td><td>datetime[Î¼s]</td><td>list[i64]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>i16</td><td>list[i16]</td><td>str</td><td>i32</td><td>i32</td><td>f32</td><td>f32</td><td>str</td></tr></thead><tbody><tr><td>3001353</td><td>&quot;Natascha var iâ€¦</td><td>&quot;Politiet frygtâ€¦</td><td>2023-06-29 06:20:33</td><td>false</td><td>&quot;Sagen om den Ã¸â€¦</td><td>2006-08-31 08:06:45</td><td>[3150850]</td><td>&quot;article_defaulâ€¦</td><td>&quot;https://ekstraâ€¦</td><td>[]</td><td>[]</td><td>[&quot;Kriminalitet&quot;, &quot;Personfarlig kriminalitet&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9955</td><td>&quot;Negative&quot;</td></tr><tr><td>3003065</td><td>&quot;Kun Star Wars â€¦</td><td>&quot;BiografgÃ¦ngernâ€¦</td><td>2023-06-29 06:20:35</td><td>false</td><td>&quot;Vatikanet har â€¦</td><td>2006-05-21 16:57:00</td><td>[3006712]</td><td>&quot;article_defaulâ€¦</td><td>&quot;https://ekstraâ€¦</td><td>[]</td><td>[]</td><td>[&quot;Underholdning&quot;, &quot;Film og tv&quot;, &quot;Ã˜konomi&quot;]</td><td>414</td><td>[433, 434]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.846</td><td>&quot;Positive&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 21)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ article_i â”† title     â”† subtitle  â”† last_modi â”† â€¦ â”† total_pag â”† total_rea â”† sentiment â”† sentimen â”‚\n",
       "â”‚ d         â”† ---       â”† ---       â”† fied_time â”†   â”† eviews    â”† d_time    â”† _score    â”† t_label  â”‚\n",
       "â”‚ ---       â”† str       â”† str       â”† ---       â”†   â”† ---       â”† ---       â”† ---       â”† ---      â”‚\n",
       "â”‚ i32       â”†           â”†           â”† datetime[ â”†   â”† i32       â”† f32       â”† f32       â”† str      â”‚\n",
       "â”‚           â”†           â”†           â”† Î¼s]       â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 3001353   â”† Natascha  â”† Politiet  â”† 2023-06-2 â”† â€¦ â”† null      â”† null      â”† 0.9955    â”† Negative â”‚\n",
       "â”‚           â”† var ikke  â”† frygter   â”† 9         â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† den       â”† nu, at    â”† 06:20:33  â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† fÃ¸rste    â”† Nataschaâ€¦ â”†           â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚ 3003065   â”† Kun Star  â”† BiografgÃ¦ â”† 2023-06-2 â”† â€¦ â”† null      â”† null      â”† 0.846     â”† Positive â”‚\n",
       "â”‚           â”† Wars      â”† ngerne    â”† 9         â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† tjente    â”† strÃ¸mmer  â”† 06:20:35  â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† mere      â”† ind forâ€¦  â”†           â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles = pl.read_parquet(PATH.joinpath(\"ebnerd_small/articles.parquet\"))\n",
    "df_articles.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init model using HuggingFace's tokenizer and wordembedding\n",
    "In the original implementation, they use the GloVe embeddings and tokenizer. To get going fast, we'll use a multilingual LLM from Hugging Face. \n",
    "Utilizing the tokenizer to tokenize the articles and the word-embedding to init NRMS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\anaconda3\\envs\\DeepLearning\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "TRANSFORMER_MODEL_NAME = \"FacebookAI/xlm-roberta-base\"\n",
    "TEXT_COLUMNS_TO_USE = [DEFAULT_SUBTITLE_COL, DEFAULT_TITLE_COL]\n",
    "MAX_TITLE_LENGTH = 30\n",
    "\n",
    "# LOAD HUGGINGFACE:\n",
    "transformer_model = AutoModel.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "transformer_tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "\n",
    "# We'll init the word embeddings using the\n",
    "word2vec_embedding = get_transformers_word_embeddings(transformer_model)\n",
    "#\n",
    "df_articles, cat_cal = concat_str_columns(df_articles, columns=TEXT_COLUMNS_TO_USE)\n",
    "df_articles, token_col_title = convert_text2encoding_with_transformers(\n",
    "    df_articles, transformer_tokenizer, cat_cal, max_length=MAX_TITLE_LENGTH\n",
    ")\n",
    "# =>\n",
    "article_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, value_col=token_col_title\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate the dataloaders\n",
    "In the implementations we have disconnected the models and data. Hence, you should built a dataloader that fits your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = NRMSDataLoader(\n",
    "    behaviors=df_train,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=False,\n",
    "    batch_size=32,\n",
    ")\n",
    "val_dataloader = NRMSDataLoader(\n",
    "    behaviors=df_validation,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=True,\n",
    "    batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Using device: cpu\n",
      "torch.Size([250002, 768])\n",
      "NewsEncoder(\n",
      "  (embedding): Embedding(250002, 768)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (multihead_attention): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (attention): AttLayer2()\n",
      ")\n",
      "UserEncoder(\n",
      "  (news_encoder): NewsEncoder(\n",
      "    (embedding): Embedding(250002, 768)\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "    (multihead_attention): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "    )\n",
      "    (attention): AttLayer2()\n",
      "  )\n",
      "  (multihead_attention): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (additive_attention): AttLayer2()\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "NRMSModel(\n",
      "  (news_encoder): NewsEncoder(\n",
      "    (embedding): Embedding(250002, 768)\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "    (multihead_attention): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "    )\n",
      "    (attention): AttLayer2()\n",
      "  )\n",
      "  (user_encoder): UserEncoder(\n",
      "    (news_encoder): NewsEncoder(\n",
      "      (embedding): Embedding(250002, 768)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (multihead_attention): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (attention): AttLayer2()\n",
      "    )\n",
      "    (multihead_attention): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "    )\n",
      "    (additive_attention): AttLayer2()\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_6748\\2502751128.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  his_input_title = torch.tensor(his_input_title, dtype=torch.long).to(device)\n",
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_6748\\2502751128.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred_input_title = torch.tensor(pred_input_title, dtype=torch.long).to(device)\n",
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_6748\\2502751128.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels, dtype=torch.long).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 30, 768])\n",
      "torch.Size([5, 30, 768])\n",
      "torch.Size([5, 30, 768])\n",
      "torch.Size([5, 30, 768])\n",
      "torch.Size([5, 30, 768])\n",
      "torch.Size([5, 30, 768])\n",
      "torch.Size([5, 30, 768])\n",
      "torch.Size([5, 30, 768])\n",
      "torch.Size([5, 30, 768])\n",
      "torch.Size([5, 30, 768])\n",
      "torch.Size([5, 30, 768])\n",
      "torch.Size([5, 30, 768])\n",
      "torch.Size([5, 30, 768])\n",
      "torch.Size([5, 30, 768])\n",
      "torch.Size([5, 30, 768])\n",
      "torch.Size([5, 30, 768])\n",
      "torch.Size([5, 30, 768])\n",
      "torch.Size([5, 30, 768])\n",
      "torch.Size([5, 30, 768])\n",
      "torch.Size([5, 30, 768])\n",
      "torch.Size([5, 30, 768])\n",
      "torch.Size([5, 30, 768])\n",
      "torch.Size([5, 30, 768])\n",
      "torch.Size([5, 30, 768])\n",
      "torch.Size([5, 30, 768])\n",
      "torch.Size([5, 30, 768])\n",
      "torch.Size([5, 30, 768])\n",
      "torch.Size([5, 30, 768])\n",
      "torch.Size([5, 30, 768])\n",
      "torch.Size([5, 30, 768])\n",
      "torch.Size([5, 30, 768])\n",
      "torch.Size([5, 30, 768])\n",
      "torch.Size([320, 30, 768])\n",
      "torch.Size([5, 32, 768])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 's'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(labels, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Zero the gradients\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnrms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhis_input_title\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_input_title\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m     28\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, labels)  \u001b[38;5;66;03m# Compute the loss\u001b[39;00m\n\u001b[0;32m     29\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\DeepLearning\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\DeepLearning\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\OneDrive - Danmarks Tekniske Universitet\\Autumn-2024\\news-recommendation\\src\\ebrec\\models\\newsrec_pytorch\\NRMSModel.py:19\u001b[0m, in \u001b[0;36mNRMSModel.forward\u001b[1;34m(self, his_input_title, pred_input_title)\u001b[0m\n\u001b[0;32m     17\u001b[0m user_present \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_encoder(his_input_title)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(news_present\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43muser_present\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ms\u001b[49m)\n\u001b[0;32m     20\u001b[0m preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(news_present, user_present\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     21\u001b[0m preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(preds, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 's'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "epoch = 0\n",
    "num_epochs = 100\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\">> Using device: {device}\")\n",
    "from ebrec.models.newsrec_pytorch import NRMSModel\n",
    "\n",
    "word2vec_embedding = torch.tensor(word2vec_embedding, dtype=torch.float32).to(device)\n",
    "print(word2vec_embedding.shape)\n",
    "nrms = NRMSModel(hparams_nrms=hparams_nrms, word2vec_embedding=word2vec_embedding, seed=42)\n",
    "print(nrms)\n",
    "optimizer = torch.optim.Adam(nrms.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    nrms.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    for i, ((his_input_title, pred_input_title), labels) in enumerate(train_dataloader):\n",
    "        his_input_title = torch.tensor(his_input_title, dtype=torch.long).to(device)\n",
    "        pred_input_title = torch.tensor(pred_input_title, dtype=torch.long).to(device)\n",
    "        labels = torch.tensor(labels, dtype=torch.long).to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = nrms(his_input_title, pred_input_title)  # Forward pass\n",
    "        loss = loss_fn(outputs, labels)  # Compute the loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update the parameters\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  # Print every 100 mini-batches\n",
    "            print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 100:.3f}\")\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 597s 8s/step - loss: 1.5952 - val_loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"NRMS\"\n",
    "LOG_DIR = f\"downloads/runs/{MODEL_NAME}\"\n",
    "MODEL_WEIGHTS = f\"downloads/data/state_dict/{MODEL_NAME}/weights\"\n",
    "\n",
    "# CALLBACKS\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR, histogram_freq=1)\n",
    "# early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2)\n",
    "# modelcheckpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "#     filepath=MODEL_WEIGHTS, save_best_only=True, save_weights_only=True, verbose=1\n",
    "# )\n",
    "\n",
    "hparams_nrms.history_size = HISTORY_SIZE\n",
    "\n",
    "\n",
    "model = NRMSModel(\n",
    "    hparams=hparams_nrms,\n",
    "    word2vec_embedding=word2vec_embedding,\n",
    "    seed=42,\n",
    ")\n",
    "hist = model.model.fit(\n",
    "    train_dataloader,\n",
    "    validation_data=val_dataloader,\n",
    "    epochs=1,\n",
    "    # callbacks=[tensorboard_callback, early_stopping, modelcheckpoint],\n",
    ")\n",
    "# Uncomment the following line if you have pre-trained weights\n",
    "# _ = model.model.load_weights(filepath=MODEL_WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example how to compute some metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153/153 [==============================] - 383s 2s/step\n"
     ]
    }
   ],
   "source": [
    "pred_validation = model.scorer.predict(val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the predictions to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>labels</th><th>scores</th><th>is_known_user</th><th>ranked_scores</th></tr><tr><td>u32</td><td>list[i32]</td><td>list[i32]</td><td>list[i32]</td><td>u32</td><td>list[i8]</td><td>list[f64]</td><td>bool</td><td>list[i64]</td></tr></thead><tbody><tr><td>386380</td><td>[9779867, 9779423, â€¦ 9779956]</td><td>[9787931, 9780460, â€¦ 9765777]</td><td>[9787465]</td><td>43657242</td><td>[0, 0, â€¦ 0]</td><td>[0.456477, 0.528305, â€¦ 0.508259]</td><td>true</td><td>[35, 13, â€¦ 23]</td></tr><tr><td>177925</td><td>[9777910, 9777769, â€¦ 9779511]</td><td>[8560195, 9486080, â€¦ 9790091]</td><td>[9789922]</td><td>110129832</td><td>[0, 0, â€¦ 0]</td><td>[0.520847, 0.433627, â€¦ 0.570924]</td><td>false</td><td>[3, 6, â€¦ 1]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 9)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ user_id â”† article_id â”† article_i â”† article_i â”† â€¦ â”† labels    â”† scores    â”† is_known_ â”† ranked_sc â”‚\n",
       "â”‚ ---     â”† _fixed     â”† ds_inview â”† ds_clicke â”†   â”† ---       â”† ---       â”† user      â”† ores      â”‚\n",
       "â”‚ u32     â”† ---        â”† ---       â”† d         â”†   â”† list[i8]  â”† list[f64] â”† ---       â”† ---       â”‚\n",
       "â”‚         â”† list[i32]  â”† list[i32] â”† ---       â”†   â”†           â”†           â”† bool      â”† list[i64] â”‚\n",
       "â”‚         â”†            â”†           â”† list[i32] â”†   â”†           â”†           â”†           â”†           â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 386380  â”† [9779867,  â”† [9787931, â”† [9787465] â”† â€¦ â”† [0, 0, â€¦  â”† [0.456477 â”† true      â”† [35, 13,  â”‚\n",
       "â”‚         â”† 9779423, â€¦ â”† 9780460,  â”†           â”†   â”† 0]        â”† ,         â”†           â”† â€¦ 23]     â”‚\n",
       "â”‚         â”† 9779956]   â”† â€¦         â”†           â”†   â”†           â”† 0.528305, â”†           â”†           â”‚\n",
       "â”‚         â”†            â”† 9765777]  â”†           â”†   â”†           â”† â€¦         â”†           â”†           â”‚\n",
       "â”‚         â”†            â”†           â”†           â”†   â”†           â”† 0.508259] â”†           â”†           â”‚\n",
       "â”‚ 177925  â”† [9777910,  â”† [8560195, â”† [9789922] â”† â€¦ â”† [0, 0, â€¦  â”† [0.520847 â”† false     â”† [3, 6, â€¦  â”‚\n",
       "â”‚         â”† 9777769, â€¦ â”† 9486080,  â”†           â”†   â”† 0]        â”† ,         â”†           â”† 1]        â”‚\n",
       "â”‚         â”† 9779511]   â”† â€¦         â”†           â”†   â”†           â”† 0.433627, â”†           â”†           â”‚\n",
       "â”‚         â”†            â”† 9790091]  â”†           â”†   â”†           â”† â€¦         â”†           â”†           â”‚\n",
       "â”‚         â”†            â”†           â”†           â”†   â”†           â”† 0.570924] â”†           â”†           â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation = add_prediction_scores(df_validation, pred_validation.tolist()).pipe(\n",
    "    add_known_user_column, known_users=df_train[DEFAULT_USER_COL]\n",
    ")\n",
    "df_validation.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MetricEvaluator class>: \n",
       " {\n",
       "    \"auc\": 0.523276170069743,\n",
       "    \"mrr\": 0.3271357380208631,\n",
       "    \"ndcg@5\": 0.368758819449155,\n",
       "    \"ndcg@10\": 0.44821698782392533\n",
       "}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = MetricEvaluator(\n",
    "    labels=df_validation[\"labels\"].to_list(),\n",
    "    predictions=df_validation[\"scores\"].to_list(),\n",
    "    metric_functions=[AucScore(), MrrScore(), NdcgScore(k=5), NdcgScore(k=10)],\n",
    ")\n",
    "metrics.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>labels</th><th>scores</th><th>is_known_user</th><th>ranked_scores</th></tr><tr><td>u32</td><td>list[i32]</td><td>list[i32]</td><td>list[i32]</td><td>u32</td><td>list[i8]</td><td>list[f64]</td><td>bool</td><td>list[i64]</td></tr></thead><tbody><tr><td>386380</td><td>[9779867, 9779423, â€¦ 9779956]</td><td>[9787931, 9780460, â€¦ 9765777]</td><td>[9787465]</td><td>43657242</td><td>[0, 0, â€¦ 0]</td><td>[0.456477, 0.528305, â€¦ 0.508259]</td><td>true</td><td>[35, 13, â€¦ 23]</td></tr><tr><td>177925</td><td>[9777910, 9777769, â€¦ 9779511]</td><td>[8560195, 9486080, â€¦ 9790091]</td><td>[9789922]</td><td>110129832</td><td>[0, 0, â€¦ 0]</td><td>[0.520847, 0.433627, â€¦ 0.570924]</td><td>false</td><td>[3, 6, â€¦ 1]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 9)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ user_id â”† article_id â”† article_i â”† article_i â”† â€¦ â”† labels    â”† scores    â”† is_known_ â”† ranked_sc â”‚\n",
       "â”‚ ---     â”† _fixed     â”† ds_inview â”† ds_clicke â”†   â”† ---       â”† ---       â”† user      â”† ores      â”‚\n",
       "â”‚ u32     â”† ---        â”† ---       â”† d         â”†   â”† list[i8]  â”† list[f64] â”† ---       â”† ---       â”‚\n",
       "â”‚         â”† list[i32]  â”† list[i32] â”† ---       â”†   â”†           â”†           â”† bool      â”† list[i64] â”‚\n",
       "â”‚         â”†            â”†           â”† list[i32] â”†   â”†           â”†           â”†           â”†           â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 386380  â”† [9779867,  â”† [9787931, â”† [9787465] â”† â€¦ â”† [0, 0, â€¦  â”† [0.456477 â”† true      â”† [35, 13,  â”‚\n",
       "â”‚         â”† 9779423, â€¦ â”† 9780460,  â”†           â”†   â”† 0]        â”† ,         â”†           â”† â€¦ 23]     â”‚\n",
       "â”‚         â”† 9779956]   â”† â€¦         â”†           â”†   â”†           â”† 0.528305, â”†           â”†           â”‚\n",
       "â”‚         â”†            â”† 9765777]  â”†           â”†   â”†           â”† â€¦         â”†           â”†           â”‚\n",
       "â”‚         â”†            â”†           â”†           â”†   â”†           â”† 0.508259] â”†           â”†           â”‚\n",
       "â”‚ 177925  â”† [9777910,  â”† [8560195, â”† [9789922] â”† â€¦ â”† [0, 0, â€¦  â”† [0.520847 â”† false     â”† [3, 6, â€¦  â”‚\n",
       "â”‚         â”† 9777769, â€¦ â”† 9486080,  â”†           â”†   â”† 0]        â”† ,         â”†           â”† 1]        â”‚\n",
       "â”‚         â”† 9779511]   â”† â€¦         â”†           â”†   â”†           â”† 0.433627, â”†           â”†           â”‚\n",
       "â”‚         â”†            â”† 9790091]  â”†           â”†   â”†           â”† â€¦         â”†           â”†           â”‚\n",
       "â”‚         â”†            â”†           â”†           â”†   â”†           â”† 0.570924] â”†           â”†           â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation = df_validation.with_columns(\n",
    "    pl.col(\"scores\")\n",
    "    .map_elements(lambda x: list(rank_predictions_by_score(x)))\n",
    "    .alias(\"ranked_scores\")\n",
    ")\n",
    "df_validation.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is using the validation, simply add the testset to your flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2446it [00:00, 23282.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipping downloads\\predictions.txt to downloads\\predictions.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "write_submission_file(\n",
    "    impression_ids=df_validation[DEFAULT_IMPRESSION_ID_COL],\n",
    "    prediction_scores=df_validation[\"ranked_scores\"],\n",
    "    path=\"downloads/predictions.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE ğŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
